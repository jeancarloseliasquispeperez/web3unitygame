# train.py

import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments
from datasets import Dataset
import torch
import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

class VulnerabilityDetectionTrainer:
    def __init__(self, model_name="microsoft/codebert-base", num_labels=2):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)

    def preprocess(self, examples):
        return self.tokenizer(examples['code_snippet'], truncation=True, padding="max_length", max_length=512)

    def compute_metrics(self, eval_pred):
        logits, labels = eval_pred
        predictions = np.argmax(logits, axis=-1)
        precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')
        acc = accuracy_score(labels, predictions)
        return {
            'accuracy': acc,
            'f1': f1,
            'precision': precision,
            'recall': recall
        }

    def load_dataset(self, csv_path):
        df = pd.read_csv(csv_path)
        dataset = Dataset.from_pandas(df)
        dataset = dataset.map(self.preprocess, batched=True)
        dataset = dataset.rename_column("label", "labels")
        dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])
        return dataset.train_test_split(test_size=0.2)

    def train(self, dataset, output_dir="./vuln_model"):
        args = TrainingArguments(
            output_dir=output_dir,
            evaluation_strategy="epoch",
            save_strategy="epoch",
            learning_rate=2e-5,
            per_device_train_batch_size=8,
            per_device_eval_batch_size=8,
            num_train_epochs=3,
            weight_decay=0.01,
            save_total_limit=2,
        )

        trainer = Trainer(
            model=self.model,
            args=args,
            train_dataset=dataset['train'],
            eval_dataset=dataset['test'],
            compute_metrics=self.compute_metrics,
        )

        trainer.train()
        trainer.save_model(output_dir)

if __name__ == "__main__":
    csv_path = "vulnerability_dataset.csv"  # path to your dataset
    trainer = VulnerabilityDetectionTrainer()
    dataset = trainer.load_dataset(csv_path)
    trainer.train(dataset)
